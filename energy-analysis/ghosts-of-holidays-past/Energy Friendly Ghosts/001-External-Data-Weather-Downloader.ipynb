{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "99490e1e-8e27-4195-92d4-a0c75589694f",
   "metadata": {},
   "source": [
    "# Introduction\n",
    "\n",
    "- Overview\n",
    "  - This notebook supplements the primary one, focusing on retrieving historical weather data for the Scrooge Building in 2018. The data is sourced from https://home.openweathermap.org/.\n",
    "  - The (downloadedd) historical weather json files will be stored in the weather directory.\n",
    "\n",
    "  - Further details regarding the importance and the usage of this data source will be described in the main notebook.\n",
    "\n",
    "- Notes\n",
    "  - In order to execute properly the code, we need an api key from the data provider at https://home.openweathermap.org/api_keys.\n",
    "  - We could skip this notebook if we just extract the weather.zip file into the ./weather directory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99c2ada8-182a-4bc7-8407-797d36fcacdf",
   "metadata": {},
   "source": [
    "# Settings "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "46a49586-68e0-4eb7-8102-668985046dcc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/motoki/miniconda3/envs/py39_holiday/bin/python\n",
      "Python 3.9.18\n"
     ]
    }
   ],
   "source": [
    "!which python\n",
    "!python --version\n",
    "\n",
    "input_dir = \"./\"\n",
    "weather_dir = f\"{input_dir}/weather\"\n",
    "!mkdir -p $weather_dir\n",
    "\n",
    "# scrooge_metadata.parquet\n",
    "# \t            in.weather_file_latitude\tin.weather_file_longitude\n",
    "# bldg_scrooge\t42.15714285714286\t        -71.15857142857143\n",
    "\n",
    "lat = 42.15714285714286 # \n",
    "lon = -71.15857142857143\n",
    "\n",
    "API_key = \"api_key\"\n",
    "api_template_url = \"https://api.openweathermap.org/data/3.0/onecall/timemachine?lat={lat}&lon={lon}&dt={dt}&appid={API_key}\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "56d82d4b-adfa-4ba0-b619-bc7d3e719737",
   "metadata": {},
   "source": [
    "# Utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b322a0f3-67a9-4183-abf6-2c235a2e20b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "\n",
    "import requests\n",
    "import json\n",
    "from tqdm import tqdm\n",
    "\n",
    "import time\n",
    "import datetime\n",
    "\n",
    "def download_json_from_api(api_url, output_file_path):\n",
    "    try:\n",
    "        headers = {\n",
    "            'Content-Type': 'application/vnd.api+json',\n",
    "        }\n",
    "        response = requests.get(api_url, headers=headers)\n",
    "\n",
    "        if response.status_code == 200: # Check if the request was successful (status code 200)\n",
    "            json_data = response.json()\n",
    "            with open(output_file_path, 'w') as file:\n",
    "                json.dump(json_data, file, indent=2)\n",
    "\n",
    "            return 0\n",
    "        else:\n",
    "            print(f\"Failed to download JSON data. Status code: {response.status_code}\")\n",
    "            return response.status_code\n",
    "\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred: {e}\")\n",
    "        return -1\n",
    "\n",
    "def download_json_from_api_retry(api_url, output_file_path, \n",
    "                                 nb_tries=5, skip_existing=True):\n",
    "    code = 0\n",
    "\n",
    "    if skip_existing and os.path.exists(output_file_path):\n",
    "        return code\n",
    "\n",
    "    for i in range(nb_tries):\n",
    "        code = download_json_from_api(api_url, output_file_path)\n",
    "        if code == 0:\n",
    "            return code\n",
    "    return code\n",
    "\n",
    "def get_unix_timestamp(str_timestamp):\n",
    "    d = datetime.datetime.strptime(str_timestamp, '%Y-%m-%d %H:%M:%S')\n",
    "    return int(d.timestamp())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2dd63394-0bef-404b-80c0-9aabd05d7e91",
   "metadata": {},
   "source": [
    "# Execution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5f0eb4c5-6848-4d3f-9a92-7e47f3363727",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(365, ['2018-01-01', '2018-01-02'], ['2018-12-30', '2018-12-31'])"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "d1 = datetime.date(2018, 1, 1)\n",
    "d2 = datetime.date(2018, 12, 31)\n",
    "days = [d1 + datetime.timedelta(days=x) for x in range((d2-d1).days + 1)]\n",
    "\n",
    "all_dates = [day.strftime('%Y-%m-%d') for day in days] \n",
    "len(all_dates), all_dates[:2], all_dates[-2:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c329237a-3330-4cc0-96c5-b6af384e61c0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Running for 28 timestamps (per day)\n",
      "['17:00:00', '17:15:00', '17:30:00', '17:45:00', '18:00:00', '18:15:00', '18:30:00', '18:45:00', '19:00:00', '19:15:00', '19:30:00', '19:45:00', '20:00:00', '20:15:00', '20:30:00', '20:45:00', '21:00:00', '21:15:00', '21:30:00', '21:45:00', '22:00:00', '22:15:00', '22:30:00', '22:45:00', '23:00:00', '23:15:00', '23:30:00', '23:45:00']\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|████████████████████████████████████████████████████████| 365/365 [00:00<00:00, 836.21it/s]\n"
     ]
    }
   ],
   "source": [
    "weather_hours  = [\"17:00:00\", \"17:15:00\", \"17:30:00\", \"17:45:00\"]\n",
    "weather_hours += [\"18:00:00\", \"18:15:00\", \"18:30:00\", \"18:45:00\"]\n",
    "weather_hours += [\"19:00:00\", \"19:15:00\", \"19:30:00\", \"19:45:00\"]\n",
    "weather_hours += [\"20:00:00\", \"20:15:00\", \"20:30:00\", \"20:45:00\"]\n",
    "weather_hours += [\"21:00:00\", \"21:15:00\", \"21:30:00\", \"21:45:00\"]\n",
    "weather_hours += [\"22:00:00\", \"22:15:00\", \"22:30:00\", \"22:45:00\"]\n",
    "weather_hours += [\"23:00:00\", \"23:15:00\", \"23:30:00\", \"23:45:00\"]\n",
    "\n",
    "weather_hours = list(set(weather_hours))\n",
    "weather_hours.sort()\n",
    "\n",
    "print(f\"Running for {len(set(weather_hours))} timestamps (per day)\")\n",
    "print(weather_hours)\n",
    "\n",
    "for weather_date in tqdm(all_dates):\n",
    "    for weather_hour in weather_hours:\n",
    "        str_timestamp = weather_date + \" \" + weather_hour\n",
    "        dt = int(get_unix_timestamp(str_timestamp))\n",
    "        api_url = api_template_url.format(lat=lat, lon=lon, dt=dt, API_key=API_key)\n",
    "\n",
    "        str_timestamp = str_timestamp.replace(\"-\", \"\").replace(\":\", \"\").replace(\" \", \"_\")\n",
    "        output_filename = f\"{weather_dir}/scrooge_{str_timestamp}_{dt}.json\"\n",
    "        download_json_from_api_retry(api_url, output_filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c7abc5b-5acd-4fa9-8e9c-1b132f67d0e1",
   "metadata": {},
   "source": [
    "# Next steps\n",
    "- Run the main notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a5c44c3-c211-46f1-bf03-e448e3cc3cd2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
